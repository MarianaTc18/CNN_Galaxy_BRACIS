{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LprY72r_YSYJ"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow\n",
        "!pip install tensorflow_probability\n",
        "!pip install git+https://github.com/henrysky/astroNN.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VPqqjNfxYXvx"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras import utils\n",
        "\n",
        "import numpy as np\n",
        "import pylab as plt\n",
        "import random\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from astroNN.models import Galaxy10CNN\n",
        "from astroNN.datasets import load_galaxy10sdss\n",
        "from astroNN.datasets.galaxy10sdss import galaxy10cls_lookup, galaxy10_confusion\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications.vgg19 import preprocess_input\n",
        "from tensorflow.keras.applications import VGG19\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Input, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.callbacks import History\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score, average_precision_score, roc_curve, precision_recall_curve\n",
        "from sklearn.preprocessing import LabelEncoder, label_binarize\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d5rtpsRDYexD"
      },
      "outputs": [],
      "source": [
        "images, labels = load_galaxy10sdss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GwOAHZv-7ucQ"
      },
      "outputs": [],
      "source": [
        "train_images, temp_images, train_labels, temp_labels = train_test_split(\n",
        "    images, labels, test_size=0.3, random_state=42, stratify=labels\n",
        ")\n",
        "\n",
        "val_images, test_images, val_labels, test_labels = train_test_split(\n",
        "    temp_images, temp_labels, test_size=0.5, random_state=42, stratify=temp_labels\n",
        ")\n",
        "num_classes = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R2xxxRdFK6fO"
      },
      "outputs": [],
      "source": [
        "train_labels_categorical = utils.to_categorical(train_labels, num_classes)\n",
        "val_labels_categorical = utils.to_categorical(val_labels, num_classes)\n",
        "test_labels_categorical = utils.to_categorical(test_labels, num_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eaHF6M8dhY8H"
      },
      "outputs": [],
      "source": [
        "def cutmix_augmentation(x_batch, y_batch, alpha=1.0):\n",
        "    batch_size, h, w, c = x_batch.shape\n",
        "    lambda_ = np.random.beta(alpha, alpha)\n",
        "\n",
        "    rx = np.random.randint(w)\n",
        "    ry = np.random.randint(h)\n",
        "    rw = int(w * np.sqrt(1 - lambda_))\n",
        "    rh = int(h * np.sqrt(1 - lambda_))\n",
        "\n",
        "    x1, x2 = np.clip(rx - rw // 2, 0, w), np.clip(rx + rw // 2, 0, w)\n",
        "    y1, y2 = np.clip(ry - rh // 2, 0, h), np.clip(ry + rh // 2, 0, h)\n",
        "\n",
        "    index = np.random.permutation(batch_size)\n",
        "\n",
        "    x_cutmix = x_batch.copy()\n",
        "    y_cutmix = y_batch.copy()\n",
        "\n",
        "    x_cutmix[:, y1:y2, x1:x2, :] = x_batch[index, y1:y2, x1:x2, :]\n",
        "\n",
        "    lambda_adjusted = 1 - ((x2 - x1) * (y2 - y1)) / (w * h)\n",
        "    y_cutmix = (lambda_adjusted * y_batch + (1 - lambda_adjusted) * y_batch[index]).astype(np.float32)\n",
        "\n",
        "    return x_cutmix.astype(np.uint8), y_cutmix\n",
        "\n",
        "def balance_classes_with_cutmix(images, labels, target_samples_per_class=5000, batch_size=32, alpha=1.0):\n",
        "\n",
        "    images = images.astype(np.uint8)\n",
        "\n",
        "\n",
        "    if labels.ndim == 1 or labels.shape[1] == 1:\n",
        "        labels = tf.keras.utils.to_categorical(labels, num_classes=10).astype(np.float32)\n",
        "\n",
        "    num_classes = labels.shape[1]\n",
        "    unique_classes = np.arange(num_classes)\n",
        "    images_list, labels_list = [], []\n",
        "\n",
        "    for cls in unique_classes:\n",
        "        cls_mask = np.argmax(labels, axis=1) == cls\n",
        "        cls_images = images[cls_mask]\n",
        "        cls_labels = labels[cls_mask]\n",
        "\n",
        "        num_images_needed = target_samples_per_class - len(cls_images)\n",
        "\n",
        "        if num_images_needed > 0:\n",
        "            augmented_images, augmented_labels = [], []\n",
        "\n",
        "            while len(augmented_images) < num_images_needed:\n",
        "                batch_indices = np.random.choice(len(cls_images), batch_size, replace=True)\n",
        "                x_batch, y_batch = cls_images[batch_indices], cls_labels[batch_indices]\n",
        "\n",
        "                x_cutmix, y_cutmix = cutmix_augmentation(x_batch, y_batch, alpha=alpha)\n",
        "\n",
        "                augmented_images.extend(x_cutmix)\n",
        "                augmented_labels.extend(y_cutmix)\n",
        "\n",
        "            augmented_images = np.array(augmented_images[:num_images_needed], dtype=np.uint8)\n",
        "            augmented_labels = np.array(augmented_labels[:num_images_needed], dtype=np.float32)\n",
        "\n",
        "            cls_images = np.concatenate([cls_images, augmented_images], axis=0)\n",
        "            cls_labels = np.concatenate([cls_labels, augmented_labels], axis=0)\n",
        "\n",
        "        images_list.append(cls_images)\n",
        "        labels_list.append(cls_labels)\n",
        "\n",
        "    balanced_images = np.concatenate(images_list, axis=0).astype(np.uint8)\n",
        "    balanced_labels = np.concatenate(labels_list, axis=0).astype(np.float32)\n",
        "\n",
        "    return balanced_images, balanced_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1XVJtHt8OTKL"
      },
      "outputs": [],
      "source": [
        "balanced_images, balanced_labels_categorical = balance_classes_with_cutmix(\n",
        "    train_images,\n",
        "    train_labels_categorical,\n",
        "    target_samples_per_class=20000,\n",
        "    batch_size=8\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j2Dzg8WuRAZA"
      },
      "outputs": [],
      "source": [
        "balanced_labels_categorical = balanced_labels_categorical.astype(np.float32)\n",
        "balanced_images = balanced_images.astype(np.float32)\n",
        "val_labels_categorical = val_labels_categorical.astype(np.float32)\n",
        "val_images = val_images.astype(np.float32)\n",
        "test_labels_categorical = test_labels_categorical.astype(np.float32)\n",
        "test_images = test_images.astype(np.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4a_MObN4fi2Z"
      },
      "outputs": [],
      "source": [
        "train_images_preprocessed = preprocess_input(balanced_images)\n",
        "val_images_preprocessed = preprocess_input(val_images)\n",
        "test_images_preprocessed = preprocess_input(test_images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Y7StDYaGOKC"
      },
      "outputs": [],
      "source": [
        "base_model = VGG19(weights='imagenet', include_top=False, input_shape=(69, 69, 3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "64aa618AGSAa"
      },
      "outputs": [],
      "source": [
        "x = GlobalAveragePooling2D()(base_model.output)\n",
        "\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "\n",
        "x = Dropout(0.5)(x)\n",
        "\n",
        "outputs = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rhYaxK4ThqQX"
      },
      "outputs": [],
      "source": [
        "for layer in base_model.layers:\n",
        "    layer.trainable = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aAr-jiv7GZtO"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wqp9Y6AM6szE"
      },
      "outputs": [],
      "source": [
        "callbacks = [\n",
        "    tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True),\n",
        "    tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=1)\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MpWpYXcvGcd3"
      },
      "outputs": [],
      "source": [
        "history = model.fit(train_images_preprocessed, balanced_labels_categorical, batch_size=32, epochs=20, validation_data=(val_images_preprocessed, val_labels_categorical), callbacks=callbacks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ba6T-xmyhytd"
      },
      "outputs": [],
      "source": [
        "for layer in base_model.layers:\n",
        "    layer.trainable = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HryGv2Smh4H2"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ddsr6M29h6ij"
      },
      "outputs": [],
      "source": [
        "history_finetune = model.fit(train_images_preprocessed, balanced_labels_categorical, batch_size=32, epochs=20, validation_data=(val_images_preprocessed, val_labels_categorical), callbacks=callbacks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2E-oKdh-h8jv"
      },
      "outputs": [],
      "source": [
        "loss, accuracy = model.evaluate(test_images_preprocessed, test_labels_categorical)\n",
        "print(\"Loss:\", loss)\n",
        "print(\"Accuracy:\", accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OsvPANNVWJrl"
      },
      "outputs": [],
      "source": [
        "y_pred_proba = model.predict(test_images_preprocessed)\n",
        "\n",
        "y_pred = np.argmax(y_pred_proba, axis=1)\n",
        "\n",
        "y_true = np.argmax(test_labels_categorical, axis=1)\n",
        "\n",
        "num_classes = len(np.unique(y_true))\n",
        "y_true_one_hot = label_binarize(y_true, classes=np.arange(num_classes))\n",
        "\n",
        "roc_auc = roc_auc_score(y_true_one_hot, y_pred_proba, multi_class='ovr')\n",
        "pr_auc = average_precision_score(y_true_one_hot, y_pred_proba)\n",
        "\n",
        "print(f'ROC AUC: {roc_auc:.4f}')\n",
        "print(f'PR AUC: {pr_auc:.4f}')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
